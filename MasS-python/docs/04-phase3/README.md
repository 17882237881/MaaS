# é˜¶æ®µ3ï¼šä¼ä¸šçº§ç‰¹æ€§

> ğŸ¢ **é˜¶æ®µç›®æ ‡**ï¼šä¸ºMaaSå¹³å°æ·»åŠ ç”Ÿäº§çº§ç‰¹æ€§ï¼Œä½¿å…¶å…·å¤‡çœŸæ­£çš„é«˜å¯ç”¨ã€å¯è§‚æµ‹å’Œå¼¹æ€§èƒ½åŠ›

## é˜¶æ®µæ€»è§ˆ

### å­¦ä¹ æ—¶é—´
**4å‘¨**ï¼ˆçº¦20ä¸ªå·¥ä½œæ—¥ï¼‰

### æ ¸å¿ƒç›®æ ‡
1. æŒæ¡æ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥å¤„ç†ï¼ˆKafkaï¼‰
2. å­¦ä¼šKuberneteså®¹å™¨ç¼–æ’
3. å®ç°é™æµä¸ç†”æ–­æœºåˆ¶
4. å¤„ç†åˆ†å¸ƒå¼äº‹åŠ¡
5. æ­å»ºå®Œæ•´çš„ç›‘æ§å‘Šè­¦ä½“ç³»

### æœ€ç»ˆäº§å‡º
- âœ… Kafkaå¼‚æ­¥ä»»åŠ¡å¤„ç†æ­£å¸¸è¿è¡Œ
- âœ… Kuberneteséƒ¨ç½²é…ç½®å®Œæˆ
- âœ… é™æµå’Œç†”æ–­æœºåˆ¶ç”Ÿæ•ˆ
- âœ… åˆ†å¸ƒå¼äº‹åŠ¡ä¿éšœä¸€è‡´æ€§
- âœ… Prometheus + Grafanaç›‘æ§ä»ªè¡¨ç›˜

## æŠ€æœ¯æ ˆè¯¦è§£

### 1. Kafkaæ¶ˆæ¯é˜Ÿåˆ—

**ä»€ä¹ˆæ˜¯æ¶ˆæ¯é˜Ÿåˆ—ï¼Ÿ**
æ¶ˆæ¯é˜Ÿåˆ—åœ¨å‘é€è€…å’Œæ¥æ”¶è€…ä¹‹é—´ä¼ é€’æ¶ˆæ¯ï¼Œå®ç°äº†ç³»ç»Ÿè§£è€¦å’Œå¼‚æ­¥å¤„ç†ã€‚Pythonç‰ˆä½¿ç”¨ `confluent-kafka-python`ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- **å¼‚æ­¥å¤„ç†**ï¼šç”¨æˆ·ä¸Šä¼ æ¨¡å‹åï¼Œå¼‚æ­¥è¿›è¡ŒéªŒè¯ã€è½¬æ¢ã€éƒ¨ç½²
- **å‰Šå³°å¡«è°·**ï¼šé«˜å¹¶å‘æ—¶å°†è¯·æ±‚æ”¾å…¥é˜Ÿåˆ—ç¼“å†²
- **ç³»ç»Ÿè§£è€¦**ï¼šæœåŠ¡é—´é€šè¿‡æ¶ˆæ¯é€šä¿¡ï¼Œäº’ä¸ä¾èµ–

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| Topic | æ¶ˆæ¯çš„åˆ†ç±»ï¼ˆå¦‚ model-events, inference-tasksï¼‰ |
| Partition | Topicçš„åˆ†åŒºï¼Œå®ç°å¹¶è¡Œå¤„ç† |
| Producer | æ¶ˆæ¯ç”Ÿäº§è€… |
| Consumer | æ¶ˆæ¯æ¶ˆè´¹è€… |
| Consumer Group | æ¶ˆè´¹è€…ç»„ï¼Œç»„å†…æˆå‘˜åˆ†æ‹…æ¶ˆæ¯ |
| Offset | æ¶ˆæ¯åœ¨åˆ†åŒºä¸­çš„ä½ç½®åç§» |

### 2. Kuberneteså®¹å™¨ç¼–æ’

**ä»€ä¹ˆæ˜¯Kubernetesï¼ˆK8sï¼‰ï¼Ÿ**
Kubernetesæ˜¯å®¹å™¨ç¼–æ’å¹³å°ï¼Œè‡ªåŠ¨åŒ–éƒ¨ç½²ã€æ‰©ç¼©å®¹å’Œç®¡ç†å®¹å™¨åŒ–åº”ç”¨ã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| Pod | æœ€å°éƒ¨ç½²å•å…ƒï¼ŒåŒ…å«1+ä¸ªå®¹å™¨ |
| Deployment | ç®¡ç†Podçš„å‰¯æœ¬æ•°å’Œæ›´æ–°ç­–ç•¥ |
| Service | ä¸ºPodæä¾›ç¨³å®šçš„ç½‘ç»œç«¯å£ |
| ConfigMap | å­˜å‚¨é…ç½®æ•°æ® |
| Secret | å­˜å‚¨æ•æ„Ÿæ•°æ® |
| Ingress | HTTPè·¯ç”±è§„åˆ™ |
| HPA | è‡ªåŠ¨æ°´å¹³ä¼¸ç¼© |

### 3. é™æµä¸ç†”æ–­

**é™æµï¼ˆRate Limitingï¼‰**
é™åˆ¶å•ä½æ—¶é—´å†…çš„è¯·æ±‚æ•°é‡ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½ã€‚Pythonç‰ˆä½¿ç”¨ `slowapi`ï¼ˆåŸºäºlimitsåº“ï¼‰ã€‚

**å¸¸è§ç®—æ³•**ï¼š
1. **å›ºå®šçª—å£**ï¼šæ¯åˆ†é’Ÿæœ€å¤šNä¸ªè¯·æ±‚
2. **æ»‘åŠ¨çª—å£**ï¼šæ›´ç²¾ç¡®çš„æµé‡æ§åˆ¶
3. **ä»¤ç‰Œæ¡¶**ï¼šä»¥å›ºå®šé€Ÿç‡æ”¾å…¥ä»¤ç‰Œï¼Œæœ‰æ¡¶å®¹é‡é™åˆ¶
4. **æ¼æ¡¶**ï¼šä»¥å›ºå®šé€Ÿç‡å¤„ç†è¯·æ±‚

**ç†”æ–­ï¼ˆCircuit Breakerï¼‰**
å½“ä¸‹æ¸¸æœåŠ¡å¼‚å¸¸æ—¶è‡ªåŠ¨"åˆ‡æ–­"è¯·æ±‚ï¼Œé¿å…çº§è”æ•…éšœã€‚Pythonç‰ˆä½¿ç”¨ `pybreaker`ã€‚

**ç†”æ–­å™¨ä¸‰ç§çŠ¶æ€**ï¼š
```
Closedï¼ˆå…³é—­ï¼‰â†’ æ­£å¸¸é€šè¿‡è¯·æ±‚
    â†“ é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼
Openï¼ˆæ‰“å¼€ï¼‰â†’ æ‹’ç»æ‰€æœ‰è¯·æ±‚
    â†“ ç­‰å¾…è¶…æ—¶
Half-Openï¼ˆåŠå¼€ï¼‰â†’ å…è®¸å°‘é‡è¯·æ±‚è¯•æ¢
    â†“ æˆåŠŸåˆ™ â†’ Closed
    â†“ å¤±è´¥åˆ™ â†’ Open
```

### 4. åˆ†å¸ƒå¼äº‹åŠ¡

**ä»€ä¹ˆæ˜¯åˆ†å¸ƒå¼äº‹åŠ¡ï¼Ÿ**
è·¨å¤šä¸ªæœåŠ¡/æ•°æ®åº“çš„æ“ä½œéœ€è¦ä¿æŒåŸå­æ€§ã€‚

**å¸¸è§æ–¹æ¡ˆ**ï¼š
| æ–¹æ¡ˆ | ä¸€è‡´æ€§ | å¤æ‚åº¦ | æ€§èƒ½ |
|------|--------|--------|------|
| 2PCï¼ˆä¸¤é˜¶æ®µæäº¤ï¼‰ | å¼ºä¸€è‡´ | é«˜ | ä½ |
| Sagaæ¨¡å¼ | æœ€ç»ˆä¸€è‡´ | ä¸­ | é«˜ |
| æœ¬åœ°æ¶ˆæ¯è¡¨ | æœ€ç»ˆä¸€è‡´ | ä½ | é«˜ |
| TCC | å¼ºä¸€è‡´ | å¾ˆé«˜ | ä¸­ |

### 5. ç›‘æ§å‘Šè­¦ä½“ç³»

**å¯è§‚æµ‹æ€§ä¸‰æ”¯æŸ±**ï¼š
1. **Metricsï¼ˆæŒ‡æ ‡ï¼‰**ï¼šPrometheus + Grafanaï¼ˆæ•°å€¼æ—¶åºæ•°æ®ï¼‰
2. **Loggingï¼ˆæ—¥å¿—ï¼‰**ï¼šELK Stack / Lokiï¼ˆäº‹ä»¶æ–‡æœ¬æ•°æ®ï¼‰
3. **Tracingï¼ˆé“¾è·¯è¿½è¸ªï¼‰**ï¼šOpenTelemetry + Jaegerï¼ˆè¯·æ±‚é“¾è·¯ï¼‰

---

## èŠ‚ç‚¹è¯¦è§£

### èŠ‚ç‚¹3.1ï¼šæ¶ˆæ¯é˜Ÿåˆ—é›†æˆï¼ˆ5å¤©ï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼š
- ç†è§£æ¶ˆæ¯é˜Ÿåˆ—çš„æ ¸å¿ƒæ¦‚å¿µ
- æŒæ¡Kafka Producer/Consumerï¼ˆconfluent-kafkaï¼‰
- å®ç°å¯é æ¶ˆæ¯æŠ•é€’
- å¤„ç†æ¶ˆæ¯æ¶ˆè´¹å¤±è´¥

**Kafka Producerç¤ºä¾‹**ï¼š
```python
from confluent_kafka import Producer

conf = {
    'bootstrap.servers': 'localhost:9092',
    'client.id': 'model-registry',
}

producer = Producer(conf)

def delivery_report(err, msg):
    if err:
        logger.error(f"Delivery failed: {err}")
    else:
        logger.info(f"Message delivered to {msg.topic()} [{msg.partition()}]")

# å‘é€æ¶ˆæ¯
import json
event = {"model_id": "abc123", "action": "created", "timestamp": "2024-01-01T00:00:00"}
producer.produce(
    topic="model-events",
    key="abc123",                    # åˆ†åŒºé”®
    value=json.dumps(event).encode(),
    callback=delivery_report
)
producer.flush()  # ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
```

**Kafka Consumerç¤ºä¾‹**ï¼š
```python
from confluent_kafka import Consumer

conf = {
    'bootstrap.servers': 'localhost:9092',
    'group.id': 'model-processor',
    'auto.offset.reset': 'earliest',
    'enable.auto.commit': False,       # æ‰‹åŠ¨æäº¤ä¿è¯å¯é æ€§
}

consumer = Consumer(conf)
consumer.subscribe(['model-events'])

try:
    while True:
        msg = consumer.poll(timeout=1.0)
        if msg is None:
            continue
        if msg.error():
            logger.error(f"Consumer error: {msg.error()}")
            continue

        # å¤„ç†æ¶ˆæ¯
        event = json.loads(msg.value().decode())
        await process_model_event(event)

        # æ‰‹åŠ¨æäº¤offset
        consumer.commit(msg)
except KeyboardInterrupt:
    pass
finally:
    consumer.close()
```

**å¼‚æ­¥æ¶ˆè´¹ï¼ˆasyncioé›†æˆï¼‰**ï¼š
```python
import asyncio
from confluent_kafka import Consumer

async def consume_loop(consumer: Consumer, topics: list[str]):
    """åœ¨asyncioäº‹ä»¶å¾ªç¯ä¸­è¿è¡ŒKafkaæ¶ˆè´¹è€…"""
    consumer.subscribe(topics)
    loop = asyncio.get_event_loop()

    while True:
        msg = await loop.run_in_executor(None, consumer.poll, 1.0)
        if msg is None:
            continue
        # å¤„ç†...
```

**å®æ“ä»»åŠ¡**ï¼š
1. Docker Composeéƒ¨ç½²Kafkaå’ŒZookeeper
2. å®ç°Producerå°è£…ï¼ˆæ”¯æŒJSONåºåˆ—åŒ–ï¼‰
3. å®ç°Consumerå°è£…ï¼ˆæ”¯æŒæ‰‹åŠ¨commitï¼‰
4. Model Registryåˆ›å»ºæ¨¡å‹æ—¶å‘é€äº‹ä»¶
5. å®ç°æ¶ˆè´¹è€…å¤„ç†æ¨¡å‹äº‹ä»¶
6. å¤„ç†æ¶ˆæ¯æ¶ˆè´¹å¤±è´¥å’Œé‡è¯•

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] Kafkaé›†ç¾¤æ­£å¸¸å¯åŠ¨
- [ ] Producerèƒ½å‘é€æ¶ˆæ¯
- [ ] Consumerèƒ½æ¥æ”¶å¹¶å¤„ç†æ¶ˆæ¯
- [ ] æ¶ˆè´¹å¤±è´¥æ—¶æœ‰é‡è¯•æœºåˆ¶
- [ ] æ¶ˆæ¯ä¸ä¸¢å¤±ï¼ˆæ‰‹åŠ¨commitï¼‰

---

### èŠ‚ç‚¹3.2ï¼šå®¹å™¨åŒ–ä¸ç¼–æ’ï¼ˆ5å¤©ï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼š
- ç¼–å†™ç”Ÿäº§çº§Dockerfile
- åˆ›å»ºKubernetes Deployment/Service/ConfigMap
- ä½¿ç”¨Helmç®¡ç†éƒ¨ç½²
- é…ç½®å¥åº·æ£€æŸ¥å’Œèµ„æºé™åˆ¶

**ç”Ÿäº§çº§Python Dockerfile**ï¼š
```dockerfile
# å¤šé˜¶æ®µæ„å»º
FROM python:3.11-slim as builder

WORKDIR /app
# Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

# Install dependencies
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-cache
RUN pip install --no-cache-dir -r requirements.txt

FROM python:3.11-slim as runtime
WORKDIR /app

# å®‰å…¨ï¼šérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY . .

USER appuser
EXPOSE 8000
HEALTHCHECK --interval=30s --timeout=10s CMD curl -f http://localhost:8000/health || exit 1
CMD ["python", "-m", "uvicorn", "api_gateway.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Kubernetes Deploymentç¤ºä¾‹**ï¼š
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  labels:
    app: api-gateway
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: maas/api-gateway:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          periodSeconds: 10
        envFrom:
        - configMapRef:
            name: api-gateway-config
```

**å®æ“ä»»åŠ¡**ï¼š
1. ç¼–å†™å„æœåŠ¡çš„ç”Ÿäº§çº§Dockerfileï¼ˆå¤šé˜¶æ®µæ„å»ºï¼‰
2. åˆ›å»ºK8s Deployment/Service/ConfigMap
3. é…ç½®å¥åº·æ£€æŸ¥å’Œèµ„æºé™åˆ¶
4. ä½¿ç”¨Helmæ‰“åŒ…éƒ¨ç½²
5. é…ç½®HPAè‡ªåŠ¨ä¼¸ç¼©

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] Dockeré•œåƒæ„å»ºæˆåŠŸ
- [ ] K8s Deploymentéƒ¨ç½²æˆåŠŸ
- [ ] å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] Serviceèƒ½æ­£å¸¸è·¯ç”±
- [ ] HPAè‡ªåŠ¨ä¼¸ç¼©é…ç½®å®Œæˆ

---

### èŠ‚ç‚¹3.3ï¼šé™æµä¸ç†”æ–­ï¼ˆ4å¤©ï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼š
- å®ç°APIé™æµï¼ˆslowapiï¼‰
- å®ç°ç†”æ–­å™¨æ¨¡å¼ï¼ˆpybreakerï¼‰
- é…ç½®é™çº§ç­–ç•¥
- æ·»åŠ é™æµ/ç†”æ–­æŒ‡æ ‡

**slowapié™æµç¤ºä¾‹**ï¼š
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.get("/api/v1/models")
@limiter.limit("100/minute")
async def list_models(request: Request):
    return await service.list_models()

# åŸºäºç”¨æˆ·çš„é™æµ
@app.post("/api/v1/inference")
@limiter.limit("10/minute", key_func=lambda request: get_user_id(request))
async def inference(request: Request):
    return await service.inference()
```

**pybreakerç†”æ–­å™¨ç¤ºä¾‹**ï¼š
```python
import pybreaker

# åˆ›å»ºç†”æ–­å™¨ï¼ˆ5æ¬¡å¤±è´¥åæ‰“å¼€ï¼Œ30ç§’ååŠå¼€ï¼‰
model_breaker = pybreaker.CircuitBreaker(
    fail_max=5,
    reset_timeout=30,
    listeners=[],
)

@model_breaker
async def call_model_registry(request):
    """è°ƒç”¨Model Registryï¼ˆå¸¦ç†”æ–­ä¿æŠ¤ï¼‰"""
    response = await grpc_client.GetModel(request)
    return response

# é™çº§å¤„ç†
async def get_model_with_fallback(model_id: str):
    try:
        return await call_model_registry(model_id)
    except pybreaker.CircuitBreakerError:
        # ç†”æ–­å™¨æ‰“å¼€æ—¶çš„é™çº§ç­–ç•¥
        logger.warning("Circuit breaker is open, using cache")
        return await redis.get(f"model:{model_id}")
```

**å®æ“ä»»åŠ¡**ï¼š
1. é›†æˆslowapiå®ç°æ¥å£é™æµ
2. é›†æˆpybreakerå®ç°ç†”æ–­å™¨
3. å®ç°é™çº§ç­–ç•¥ï¼ˆç¼“å­˜å›é€€ï¼‰
4. æ·»åŠ é™æµ/ç†”æ–­PrometheusæŒ‡æ ‡
5. æµ‹è¯•å„ç§æ•…éšœåœºæ™¯

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] è¶…è¿‡é¢‘ç‡é™åˆ¶è¿”å›429
- [ ] ä¸‹æ¸¸æœåŠ¡æ•…éšœæ—¶è§¦å‘ç†”æ–­
- [ ] ç†”æ–­æ—¶èµ°é™çº§é€»è¾‘
- [ ] é™æµ/ç†”æ–­æŒ‡æ ‡å¯è§‚æµ‹

---

### èŠ‚ç‚¹3.4ï¼šåˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆ4å¤©ï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼š
- ç†è§£åˆ†å¸ƒå¼äº‹åŠ¡é—®é¢˜
- å®ç°Sagaäº‹åŠ¡ç¼–æ’
- å®ç°æœ¬åœ°æ¶ˆæ¯è¡¨æ¨¡å¼
- å¤„ç†è¡¥å¿æ“ä½œ

**Sagaæ¨¡å¼å®ç°**ï¼š
```python
from dataclasses import dataclass
from typing import Callable, Awaitable

@dataclass
class SagaStep:
    name: str
    execute: Callable[..., Awaitable]   # æ­£å‘æ“ä½œ
    compensate: Callable[..., Awaitable]  # è¡¥å¿æ“ä½œ

class SagaOrchestrator:
    def __init__(self):
        self.steps: list[SagaStep] = []
        self.completed: list[SagaStep] = []

    def add_step(self, step: SagaStep):
        self.steps.append(step)

    async def execute(self, context: dict) -> bool:
        for step in self.steps:
            try:
                await step.execute(context)
                self.completed.append(step)
            except Exception as e:
                logger.error(f"Saga step '{step.name}' failed: {e}")
                await self._compensate(context)
                return False
        return True

    async def _compensate(self, context: dict):
        """åå‘è¡¥å¿å·²å®Œæˆçš„æ­¥éª¤"""
        for step in reversed(self.completed):
            try:
                await step.compensate(context)
                logger.info(f"Compensated: {step.name}")
            except Exception as e:
                logger.error(f"Compensation failed for '{step.name}': {e}")
```

**å®æ“ä»»åŠ¡**ï¼š
1. è®¾è®¡ä¸€ä¸ªè·¨æœåŠ¡äº‹åŠ¡æµç¨‹ï¼ˆå¦‚ï¼šåˆ›å»ºæ¨¡å‹+åˆ†é…å­˜å‚¨+æ³¨å†Œç‰ˆæœ¬ï¼‰
2. å®ç°Sagaç¼–æ’å™¨
3. å®ç°æ¯æ­¥çš„è¡¥å¿æ“ä½œ
4. å®ç°æœ¬åœ°æ¶ˆæ¯è¡¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
5. æµ‹è¯•å„ç§å¤±è´¥åœºæ™¯

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] æ­£å¸¸æµç¨‹å…¨éƒ¨æ­¥éª¤æ‰§è¡ŒæˆåŠŸ
- [ ] æŸæ­¥éª¤å¤±è´¥æ—¶è¡¥å¿æ“ä½œæ‰§è¡Œ
- [ ] æœ€ç»ˆæ•°æ®ä¸€è‡´
- [ ] æ—¥å¿—è®°å½•å®Œæ•´

---

### èŠ‚ç‚¹3.5ï¼šç›‘æ§å‘Šè­¦ä½“ç³»ï¼ˆ4å¤©ï¼‰

**å­¦ä¹ ç›®æ ‡**ï¼š
- é›†æˆOpenTelemetryé“¾è·¯è¿½è¸ª
- æ­å»ºPrometheus + Grafanaç›‘æ§
- é…ç½®Alertmanagerå‘Šè­¦è§„åˆ™
- æ„å»ºç›‘æ§ä»ªè¡¨ç›˜

**OpenTelemetryé“¾è·¯è¿½è¸ªé›†æˆ**ï¼š
```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

# é…ç½®TracerProvider
tracer_provider = TracerProvider()
jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",
    agent_port=6831,
)
tracer_provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
trace.set_tracer_provider(tracer_provider)

# è‡ªåŠ¨æ³¨å…¥FastAPI
FastAPIInstrumentor.instrument_app(app)

# æ‰‹åŠ¨åˆ›å»ºSpan
tracer = trace.get_tracer(__name__)

async def create_model(data):
    with tracer.start_as_current_span("create_model") as span:
        span.set_attribute("model.name", data.name)

        # åµŒå¥—Span
        with tracer.start_as_current_span("save_to_db"):
            await repo.create(model)

        with tracer.start_as_current_span("publish_event"):
            await kafka_producer.send(event)
```

**PrometheusæŒ‡æ ‡ï¼ˆprometheus-clientï¼‰**ï¼š
```python
from prometheus_client import make_asgi_app, Counter, Histogram

# è‡ªå®šä¹‰æŒ‡æ ‡
REQUEST_COUNT = Counter(
    "app_request_count_total",
    "Total request count",
    ["method", "endpoint", "status"]
)
REQUEST_LATENCY = Histogram(
    "app_request_latency_seconds",
    "Request latency",
    ["method", "endpoint"]
)

# æŒ‚è½½/metricsç«¯ç‚¹
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

**Grafana Dashboardé…ç½®è¦ç‚¹**ï¼š
- HTTPè¯·æ±‚é€Ÿç‡ï¼ˆQPSï¼‰
- è¯·æ±‚å»¶è¿Ÿåˆ†ä½æ•°ï¼ˆP50/P95/P99ï¼‰
- é”™è¯¯ç‡
- æ´»è·ƒè¿æ¥æ•°
- æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡
- ç¼“å­˜å‘½ä¸­ç‡

**å®æ“ä»»åŠ¡**ï¼š
1. é›†æˆOpenTelemetry + Jaeger
2. é…ç½®PrometheusæŒ‡æ ‡æ”¶é›†
3. æ­å»ºGrafanaï¼Œå¯¼å…¥Dashboard
4. é…ç½®Alertmanagerå‘Šè­¦è§„åˆ™
5. éªŒè¯ç«¯åˆ°ç«¯çš„é“¾è·¯è¿½è¸ª

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] Jaegerèƒ½æŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾
- [ ] Prometheusæ”¶é›†åˆ°æ‰€æœ‰æŒ‡æ ‡
- [ ] Grafanaä»ªè¡¨ç›˜å±•ç¤ºæ­£å¸¸
- [ ] å‘Šè­¦è§„åˆ™èƒ½æ­£ç¡®è§¦å‘

---

## é˜¶æ®µ3é‡Œç¨‹ç¢‘

### å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] Kafkaå¼‚æ­¥ä»»åŠ¡å¤„ç†æ­£å¸¸è¿è¡Œ
- [ ] K8séƒ¨ç½²é…ç½®å®Œæˆï¼ŒæœåŠ¡å¯è¿è¡Œ
- [ ] é™æµè¶…è¿‡é˜ˆå€¼æ—¶è¿”å›429
- [ ] ç†”æ–­å™¨åœ¨æ•…éšœæ—¶æ­£ç¡®è§¦å‘
- [ ] åˆ†å¸ƒå¼äº‹åŠ¡æ•°æ®ä¸€è‡´
- [ ] Prometheus + Grafanaç›‘æ§å¯ç”¨
- [ ] Jaegeré“¾è·¯è¿½è¸ªå¯ç”¨
- [ ] å‘Šè­¦è§„åˆ™é…ç½®å®Œæˆ

### å¯æ¼”ç¤ºåŠŸèƒ½
1. åˆ›å»ºæ¨¡å‹ â†’ Kafkaäº‹ä»¶ â†’ å¼‚æ­¥å¤„ç†
2. é«˜å¹¶å‘è¯·æ±‚ â†’ é™æµè¿”å›429
3. å…³é—­ä¸‹æ¸¸æœåŠ¡ â†’ ç†”æ–­ â†’ é™çº§
4. Grafanaä»ªè¡¨ç›˜å±•ç¤ºQPS/å»¶è¿Ÿ/é”™è¯¯ç‡
5. Jaegerå±•ç¤ºè¯·æ±‚å…¨é“¾è·¯

### ä¸‹ä¸€æ­¥
è¿›å…¥**é˜¶æ®µ4ï¼šé«˜çº§ç‰¹æ€§ä¸ä¼˜åŒ–**ï¼Œå­¦ä¹ GPUè°ƒåº¦ã€å¤šç§Ÿæˆ·ã€æ€§èƒ½ä¼˜åŒ–å’ŒCI/CDã€‚

---

**ç»§ç»­å­¦ä¹ **ï¼š[é˜¶æ®µ4æ–‡æ¡£](../05-phase4/README.md)
